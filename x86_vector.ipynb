{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/pico/.local/lib/python3.10/site-packages (1.23.2)\n",
      "Requirement already satisfied: tqdm in /home/pico/.local/lib/python3.10/site-packages (4.64.0)\n",
      "Requirement already satisfied: pandas in /home/pico/.local/lib/python3.10/site-packages (1.4.4)\n",
      "Requirement already satisfied: gensim in /home/pico/.local/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: sklearn in /home/pico/.local/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in /home/pico/.local/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: pytorch_lightning in /home/pico/.local/lib/python3.10/site-packages (1.7.4)\n",
      "Requirement already satisfied: torchvision in /home/pico/.local/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/pico/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/pico/.local/lib/python3.10/site-packages (from gensim) (6.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/pico/.local/lib/python3.10/site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn in /home/pico/.local/lib/python3.10/site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/pico/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/pico/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/pico/.local/lib/python3.10/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pico/.local/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /home/pico/.local/lib/python3.10/site-packages (from pytorch_lightning) (0.3.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/pico/.local/lib/python3.10/site-packages (from pytorch_lightning) (0.9.3)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/pico/.local/lib/python3.10/site-packages (from pytorch_lightning) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/pico/.local/lib/python3.10/site-packages (from pytorch_lightning) (4.3.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/pico/.local/lib/python3.10/site-packages (from pytorch_lightning) (2022.8.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/lib/python3/dist-packages (from pytorch_lightning) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.9.* in /home/pico/.local/lib/python3.10/site-packages (from pytorch_lightning) (1.12.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/pico/.local/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.48.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.12.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (59.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/pico/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (2.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/pico/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/pico/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pico/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pico/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/pico/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pico/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/pico/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/pico/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/pico/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/pico/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/pico/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/pico/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/pico/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/pico/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/pico/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (3.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install some stuff\n",
    "%pip install --no-cache numpy tqdm pandas gensim sklearn matplotlib pytorch_lightning torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some things\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'authentication_required', 'availability_impact',\n",
      "       'cve_id', 'cve_page', 'cwe_id', 'access_complexity',\n",
      "       'confidentiality_impact', 'integrity_impact', 'publish_date', 'score',\n",
      "       'summary', 'update_date', 'vulnerability_classification', 'ref_link',\n",
      "       'commit_id', 'commit_message', 'files_changed', 'lang', 'project',\n",
      "       'version_after_fix', 'version_before_fix'],\n",
      "      dtype='object')\n",
      "<bound method Series.unique of 0       DoS Exec Code Overflow \n",
      "1                    Exec Code \n",
      "2                    Exec Code \n",
      "3                           NaN\n",
      "4                          DoS \n",
      "                 ...           \n",
      "4427              DoS Overflow \n",
      "4428                    Bypass \n",
      "4429                        NaN\n",
      "4430                        NaN\n",
      "4431                       DoS \n",
      "Name: vulnerability_classification, Length: 4432, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "vulns = pd.read_csv('assets/big-vul.csv')\n",
    "print(vulns.columns)\n",
    "print(vulns['vulnerability_classification'].unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████                                       | 8/32 [00:01<00:04,  5.13it/s]objdump: /bin/print: file format not recognized\n",
      "100%|███████████████████████████████████████████████████| 32/32 [00:02<00:00, 14.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Lets get some assembly data\n",
    "import os\n",
    "binary_files = os.listdir('/bin/')\n",
    "binary_files = binary_files + os.listdir('/usr/bin/')\n",
    "# All the files in /bin/*, output to ./assembly_files in x86 intel flavor syntax\n",
    "for binary in tqdm(['ssh', 'sftp', 'ls', 'cp', 'du', 'cat', \n",
    "'pwd', 'vi', 'sh', 'print', 'awk', 'ping', 'kill', 'df', 'rm', 'time', 'top', 'unzip', 'wget', 'ps',\n",
    "'gzip', 'dd', 'more', 'mkdir', 'telnet', 'su', 'uname', 'umount', 'stat', 'strings', 'echo', 'grep']):\n",
    "    os.system(f'objdump -M intel -D /bin/{binary} > assembly_files/{binary}.asm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1492/1492 [01:27<00:00, 17.05it/s]\n"
     ]
    }
   ],
   "source": [
    " # 'Normalize' all the assembly data information\n",
    " #  Example:\n",
    "\n",
    " # Raw assembly\n",
    " #  32a:\t36 2d 36 34 2e 73    \tss sub eax,0x732e3436\n",
    " #  330:\t6f                   \touts   dx,DWORD PTR ds:[rsi]\n",
    " #  331:\t2e 32 00             \tcs xor al,BYTE PTR [rax]\n",
    "\n",
    " # Normalized assembly\n",
    " #             ss sub eax,0x732e3436\n",
    " #             outs   dx,DWORD PTR ds:[rsi]\n",
    " #             cs xor al,BYTE PTR [rax]\n",
    "\n",
    "assembly_files = os.listdir('assembly_files')\n",
    "for file in tqdm(assembly_files):\n",
    "    normalized_file = open(f\"assembly_files_norm/{file}\", \"w\")\n",
    "    lines = open(f\"assembly_files/{file}\", \"r\").readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            word = line.split('\\t')[2]\n",
    "            word = ' '.join(word.split())\n",
    "            word = word.split('#', 1)[0]\n",
    "            normalized_file.write(word + '\\n')\n",
    "        except IndexError:\n",
    "            pass\n",
    "    normalized_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massembly_files_norm/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m----> 5\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m histogram\u001b[38;5;241m.\u001b[39mget(size):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m17\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histogram = {}\n",
    "for file in os.listdir('assembly_files_norm'):\n",
    "    lines = open(f\"assembly_files_norm/{file}\").readlines()\n",
    "    for line in lines:\n",
    "        size = len(line.split(' '))\n",
    "        if histogram.get(size):\n",
    "            if size == 17:\n",
    "                print(line)\n",
    "            histogram[size] = histogram[size] + 1\n",
    "        else:\n",
    "            histogram[size] = 1\n",
    "print(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how large is corupus?\n",
    "os.system('du -h ./assembly_files/')\n",
    "os.system('du -h ./assembly_files_norm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word2vec model\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import PathLineSentences\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "if not os.path.exists('x862vec.model'):\n",
    "    model = Word2Vec(sentences=PathLineSentences('assembly_files_norm'), vector_size=5, window=128, min_count=1, workers=4)\n",
    "    model.save(\"x862vec.model\")\n",
    "else:\n",
    "    model = KeyedVectors.load(\"x862vec.model\", mmap=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'ds:rsi' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/pico/Documents/x862vec/x86_vector.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m padding \u001b[39m=\u001b[39m \u001b[39m17\u001b[39m \u001b[39m-\u001b[39m size\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     vector \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mwv[word]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     vectors\u001b[39m.\u001b[39mappend(vector)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m pad \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(padding):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:404\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \n\u001b[1;32m    402\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 404\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[1;32m    406\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:447\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vector\u001b[39m(\u001b[39mself\u001b[39m, key, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    424\u001b[0m     \u001b[39m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(key)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m norm:\n\u001b[1;32m    449\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:421\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[1;32m    420\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 421\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'ds:rsi' not present\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function in assembly\n",
    "some_function = \"\"\"\n",
    "0000000000000368 <.note.gnu.build-id>:\n",
    " 36a:\t00 00                \tadd    BYTE PTR [rax],al\n",
    " 36c:\t14 00                \tadc    al,0x0\n",
    " 36e:\t00 00                \tadd    BYTE PTR [rax],al\n",
    " 370:\t03 00                \tadd    eax,DWORD PTR [rax]\n",
    " 372:\t00 00                \tadd    BYTE PTR [rax],al\n",
    " 374:\t47                   \trex.RXB\n",
    " 375:\t4e 55                \trex.WRX push rbp\n",
    " 377:\t00 d2                \tadd    dl,dl\n",
    " 379:\t6e                   \touts   dx,BYTE PTR ds:[rsi]\n",
    " 37a:\t36 82                \tss (bad) \n",
    " 37c:\t89 ac 83 53 2c 84 86 \tmov    DWORD PTR [rbx+rax*4-0x797bd3ad],ebp\n",
    " 383:\tf2 d9 01             \trepnz fld DWORD PTR [rcx]\n",
    " 386:\t35 08 af 80 2e       \txor    eax,0x2e80af08\n",
    " 38b:\t8f                   \t.byte 0x8f\n",
    "\"\"\"\n",
    "from normalizer import normalize_assembly\n",
    "data = list()\n",
    "lines = some_function.split('\\n')\n",
    "for line in lines:\n",
    "    try:\n",
    "        word = line.split('\\t')[2]\n",
    "        word = ' '.join(word.split())\n",
    "        word = word.split('#', 1)[0]\n",
    "        data.append(word)\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "vectors = list()\n",
    "sentence_vectors = list()\n",
    "for sentence in data:\n",
    "    # Get each raw token\n",
    "    words = sentence.strip().split(' ')\n",
    "    # How long is instruction? \n",
    "    size = len(words)\n",
    "    # Concat zero arrays for null instruction placeholders as padding\n",
    "    padding = 17 - size\n",
    "    \n",
    "    for word in words:\n",
    "        vector = model.wv[word]\n",
    "        vectors.append(vector)\n",
    "    for pad in range(padding):\n",
    "        vectors.append(np.zeros(16))\n",
    "    # Concat all together\n",
    "    sentence_vector = np.concatenate(vectors)\n",
    "    sentence_vectors.append(sentence_vector)\n",
    "    vectors = list()\n",
    "\n",
    "# Create a matrix from each 'sentence' vector\n",
    "matrix = np.stack(sentence_vectors)\n",
    "print(matrix.shape)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/pico/Documents/x862vec exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name    | Type        | Params\n",
      "----------------------------------------\n",
      "0 | cnv     | Conv2d      | 26    \n",
      "1 | rel     | ReLU        | 0     \n",
      "2 | bn      | BatchNorm2d | 2     \n",
      "3 | mxpool  | MaxPool2d   | 0     \n",
      "4 | flat    | Flatten     | 0     \n",
      "5 | fc1     | Linear      | 127   \n",
      "6 | fc2     | Linear      | 2     \n",
      "7 | fc3     | Linear      | 4     \n",
      "8 | softmax | Softmax     | 0     \n",
      "----------------------------------------\n",
      "161       Trainable params\n",
      "0         Non-trainable params\n",
      "161       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:218: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 133, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n    results = self._run(model, ckpt_path=self.ckpt_path)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\n    results = self._run_stage()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1252, in _run_stage\n    return self._run_train()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1274, in _run_train\n    self._run_sanity_check()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1343, in _run_sanity_check\n    val_loop.run()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n    self.advance(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 155, in advance\n    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n    self.advance(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 143, in advance\n    output = self._evaluation_step(**kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 240, in _evaluation_step\n    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1704, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp_spawn.py\", line 291, in validation_step\n    return self.model(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1008, in forward\n    output = self._run_ddp_forward(*inputs, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 971, in _run_ddp_forward\n    return module_to_run(*inputs, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py\", line 90, in forward\n    return self.module.validation_step(*inputs, **kwargs)\n  File \"/home/pico/Documents/x862vec/myconvmodel.py\", line 55, in validation_step\n    img = x.view(-1, 1, 256, 12)\nRuntimeError: shape '[-1, 1, 256, 12]' is invalid for input of size 2560\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/pico/Documents/x862vec/x86_vector.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m dx \u001b[39m=\u001b[39m AssemblyLightDataset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     w2v_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m16\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39massets/data\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     matrix_size\u001b[39m=\u001b[39m\u001b[39m272\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,callbacks\u001b[39m=\u001b[39m[checkpoint_callback], accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmod,datamodule\u001b[39m=\u001b[39;49mdx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pico/Documents/x862vec/x86_vector.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m trainer\u001b[39m.\u001b[39mvalidate()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:648\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    647\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mlauncher\u001b[39m.\u001b[39;49mlaunch(trainer_fn, \u001b[39m*\u001b[39;49margs, trainer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:107\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     process_args \u001b[39m=\u001b[39m [trainer, function, args, kwargs, return_queue]\n\u001b[0;32m--> 107\u001b[0m mp\u001b[39m.\u001b[39;49mstart_processes(\n\u001b[1;32m    108\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapping_function,\n\u001b[1;32m    109\u001b[0m     args\u001b[39m=\u001b[39;49mprocess_args,\n\u001b[1;32m    110\u001b[0m     nprocs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49mnum_processes,\n\u001b[1;32m    111\u001b[0m     start_method\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start_method,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    113\u001b[0m worker_output \u001b[39m=\u001b[39m return_queue\u001b[39m.\u001b[39mget()\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m trainer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[39m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39;49mjoin():\n\u001b[1;32m    199\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-- Process \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m terminated with the following error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m error_index\n\u001b[1;32m    159\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[39mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[39m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 133, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n    results = self._run(model, ckpt_path=self.ckpt_path)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\n    results = self._run_stage()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1252, in _run_stage\n    return self._run_train()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1274, in _run_train\n    self._run_sanity_check()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1343, in _run_sanity_check\n    val_loop.run()\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n    self.advance(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 155, in advance\n    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n    self.advance(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 143, in advance\n    output = self._evaluation_step(**kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 240, in _evaluation_step\n    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1704, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp_spawn.py\", line 291, in validation_step\n    return self.model(*args, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1008, in forward\n    output = self._run_ddp_forward(*inputs, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 971, in _run_ddp_forward\n    return module_to_run(*inputs, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pico/.local/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py\", line 90, in forward\n    return self.module.validation_step(*inputs, **kwargs)\n  File \"/home/pico/Documents/x862vec/myconvmodel.py\", line 55, in validation_step\n    img = x.view(-1, 1, 256, 12)\nRuntimeError: shape '[-1, 1, 256, 12]' is invalid for input of size 2560\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import pytorch_lightning as pl\n",
    "from assembly_dataset import AssemblyDataset, AssemblyLightDataset\n",
    "from myconvmodel import ConvNDModel\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='valid_loss',\n",
    "    dirpath='./',\n",
    "    filename='models-{epoch:02d}-{valid_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min') \n",
    "\n",
    "w2v_model = KeyedVectors.load(\"x862vec.model\", mmap=\"r\")\n",
    "mod = ConvNDModel()\n",
    "df = pd.read_csv(\"assets/train.csv\")\n",
    "dx = AssemblyLightDataset(\n",
    "    w2v_model,\n",
    "    16,\n",
    "    path='assets/data',\n",
    "    matrix_size=272,\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=6,callbacks=[checkpoint_callback], accelerator='cpu', devices=2)\n",
    "trainer.fit(model=mod,datamodule=dx)\n",
    "trainer.validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
